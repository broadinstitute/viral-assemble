#!/usr/bin/env python

from __future__ import print_function
import subprocess
import time
import json
import sys
import os
import os.path

from annexremote import Master
from annexremote import SpecialRemote
from annexremote import RemoteError
from annexremote import UnsupportedRequest

import tools.gcloud

#Now create your special remote class. It must subtype ``SpecialRemote`` and implement at least the 6 basic methods:

GS_URI_PFX='gs://'

def _msg(*args):
    print(*args, file=sys.stderr)

def _run(cmd):
    _msg('running command: ', cmd, 'cwd=', os.getcwd())
    beg_time = time.time()
    subprocess.check_call(cmd, shell=True)
    _msg('command succeeded in {}s: {}'.format(time.time()-beg_time, cmd))

def _run_get_output(cmd):
    _msg('running command: ', cmd)
    beg_time = time.time()
    output = subprocess.check_output(cmd, shell=True).decode('utf-8')
    _msg('command succeeded in {}s: {}'.format(time.time()-beg_time, cmd))
    return output

def _run_get_json(cmd):
    return json.loads(_run_get_output(cmd).strip())


class GSURIRemote(SpecialRemote):
    def initremote(self):
        # initialize the remote, eg. create the folders
        # raise RemoteError if the remote couldn't be initialized
        pass

    def prepare(self):
        # prepare to be used, eg. open TCP connection, authenticate with the server etc.
        # raise RemoteError if not ready to use
        pass

    def transfer_store(self, key, filename):
        # store the file in `filename` to a unique location derived from `key`
        # raise RemoteError if the file couldn't be stored
        raise RemoteError('Cannot yet store files')

    def _dbg(self, *args):
        self.annex.debug(' '.join(map(str, args)))

    def transfer_retrieve(self, key, filename):
        # get the file identified by `key` and store it to `filename`
        # raise RemoteError if the file couldn't be retrieved
        urls = self.annex.geturls(key=key, prefix=GS_URI_PFX)
        url_list = [url for url in urls if self.claimurl(url)]
        if not url_list:
            raise RemoteError('No urls for key {} filename {}'.format(key, filename))
        url = url_list[0]
        self._dbg('transfer-retrieve: key=', key, 'filename=', filename, 'urls=', urls, 'url=', url)
        try:
            #cmd = 'dx download --no-progress ' + self._url_to_dxid(url) + " -f -o '" + filename + "'"
            gcloud_tool = tools.gcloud.GCloudTool()
            gcloud_tool.download_object(gs_uri=url, destination_file_name=filename)
            #cmd = 'gsutil cp ' + url + " '" + filename + "'"
            #self._dbg('cmd=', cmd)
            #_run(cmd)
        except subprocess.CalledProcessError:
            raise RemoteError('transfer_retrieve: Error running gs download cmd {}'.format(cmd))

    def checkpresent(self, key):
        # return True if the key is present in the remote
        # return False if the key is not present
        # raise RemoteError if the presence of the key couldn't be determined, eg. in case of connection error
        _msg('CHECKPRESENT: {}'.format(key))
        self._dbg('CHECKING PRESENCE OF KEY ', key)
        urls = self.annex.geturls(key=key, prefix=GS_URI_PFX)
        self._dbg('got urls {}'.format(urls))
        url = [url for url in urls if self.claimurl(url)][0]
        self._dbg('checkpresent: key=', key, 'urls=', urls, 'url=', url)
        return bool(self.checkurl(url))
        #urls = self.annex.geturls(key=key, prefix='')
        #self._dbg('URLS=', urls)
        #return any([self.checkurl(url) for url in self.annex.geturls(key=key, prefix=GS_URI_PFX)])
        #raise RemoteError('Cannot yet check by key')

    def whereis(self, key):
        self._dbg('WHEREIS: key=', key, 'urls=', self.annex.geturls(key=key,prefix=GS_URI_PFX))
        raise UnsupportedRequest('Not supporting whereis yet')
        
    def remove(self, key):
        # remove the key from the remote
        # raise RemoteError if it couldn't be removed
        # note that removing a not existing key isn't considered an error
        raise RemoteError('Cannot yet remove keys')

    def claimurl(self, url):
        return url.startswith(GS_URI_PFX)

    def checkurl(self, url):
        if not self.claimurl(url): raise RemoteError('Cannot check non-gs URL {}'.format(url))
        try:
            gcloud_tool = tools.gcloud.GCloudTool()
            mdata = gcloud_tool.get_metadata_for_objects([url])
            return [dict(size=int(mdata[url]['size']), filename=os.path.basename(url))]
            # stat_output = _run_get_output('gsutil stat ' + url)
            # self._dbg('TYPE ORIG IS ', type(stat_output))
            # stat_output = str(stat_output)
            # self._dbg('TYPE at 1 IS ', type(stat_output))
            # stat_output = stat_output.strip()
            # self._dbg('TYPE at 2 IS ', type(stat_output))
            # stat_output = stat_output.split('\n')
            # self._dbg('LINES', len(stat_output))
            # for line in stat_output:
            #     line = str(line)
            #     self._dbg('LINE', line)
            #     fields = line.strip().split()
            #     if len(fields) == 2 and fields[0] == 'Content-Length:':
                    
        except subprocess.CalledProcessError:
            raise RemoteError('Could not stat url')

# In your ``main`` function, link your remote to the master class and initialize the protocol:

def main():
    master = Master()
    remote = GSURIRemote(master)
    master.LinkRemote(remote)
    master.Listen()

if __name__ == "__main__":
    main()

